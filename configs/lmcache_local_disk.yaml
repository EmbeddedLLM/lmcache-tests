chunk_size: 256
local_device: "file:///local/lmcache-tests/"
remote_url: null
remote_serde: "cachegen"

# Whether retrieve() is pipelined or not
pipelined_backend: True

# Whether saving decode KV cache to boost multi-turn conversation or not
save_decode_cache: True
